{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio 9 - EoML Nathalia Morales.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathsmo/Elements-of-ML/blob/master/Laboratorio_9_EoML_Nathalia_Morales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogh-5HfiUKBJ",
        "colab_type": "text"
      },
      "source": [
        "# Laboratorio 9 - Nathalia Morales\n",
        "\n",
        "En este laboratorio usaremos boosting sobre árboles de decisión y exploraremos cómo optimizar el modelo respecto a los parámetros de boosting (número de árboles, rapidez de aprendizaje y profundidad)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqj79xiaUPOV",
        "colab_type": "code",
        "outputId": "81f11916-cb89-4221-98ad-d7899178d6f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import statsmodels\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "print(\"Todos los paquetes han sido importados:\")\n",
        "\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Todos los paquetes han sido importados:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRzhSNwbvMo6",
        "colab_type": "text"
      },
      "source": [
        "Trabajaremos sobre la base de datos de casas de Boston de skLearn. Para la implementación del GradientBoosting, puedes referirte a un ejemplo con datos del Titanic en [Medium](https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko4t_pwmFILg",
        "colab_type": "text"
      },
      "source": [
        "## 1.   Clasifica los precios de casas en categorías ordenadas. Esta nueva variable será tu target.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ivn5XuDFPgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()\n",
        "data = pd.DataFrame(boston.data)\n",
        "data.columns = boston.feature_names\n",
        "data['PRICE'] = boston.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iHrEwmtsr92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['clas'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT6-mFQrqHXi",
        "colab_type": "code",
        "outputId": "784d5b21-3016-4ed5-c2b3-927e90e746d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "for i in range(0,len(data['PRICE'])):\n",
        "  if data['PRICE'][i] >= 5 and data['PRICE'][i]< 15:\n",
        "    data['clas'][i] = 1\n",
        "  elif data['PRICE'][i] >= 15 and data['PRICE'][i]< 25:\n",
        "    data['clas'][i] = 2\n",
        "  elif data['PRICE'][i] >= 25 and data['PRICE'][i]< 35:\n",
        "    data['clas'][i] = 3 \n",
        "  elif data['PRICE'][i] >= 35 and data['PRICE'][i]< 45:\n",
        "    data['clas'][i] = 4\n",
        "  elif data['PRICE'][i] >= 45 and data['PRICE'][i]< 55:\n",
        "    data['clas'][i] = 5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dtooJa7stoY",
        "colab_type": "code",
        "outputId": "dfb73265-006e-4668-dd93-2dc93da02afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data['clas'].unique()\n",
        "#no deberian de haber 0's"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 4, 1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmhojITPAIl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2 = data[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
        "       'PTRATIO', 'B', 'LSTAT']]\n",
        "aim = data['clas']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AszG9uttuEm3",
        "colab_type": "text"
      },
      "source": [
        "Clases de 1 - 5 por grupos de 10 desde 5 - 14.99"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB9fh1wJFRES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(data2, aim, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe9hTPWySzP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(model):\n",
        "\n",
        "    # fit the model with X_train_scaled, y_train\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # predict the test labels\n",
        "    prediction = model.predict(x_test)\n",
        "\n",
        "    # evaluate the model\n",
        "    train_score = model.score(x_train, y_train)\n",
        "    test_score = model.score(x_test, y_test)\n",
        "\n",
        "    print('Train Score: '+ str(train_score))\n",
        "    print('Test Score:' + str(test_score))\n",
        "    print('')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxSs3giLFJyd",
        "colab_type": "text"
      },
      "source": [
        "## 2.   Haz el Boosting usando valores para el *learning rate*: 1, 0.5, 0.25, 0.1, 0.05, 0.01. Utiliza alguna medida apropiada para medir la efectividad del modelo en cada caso y busca un valor óptimo. **Explica las ventajas y desventajas de un aprendizaje rápido contra uno lento.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0QUaEuuS0fS",
        "colab_type": "code",
        "outputId": "6428cdc4-1484-4582-ef9d-b240b2cb3cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "list_learning_rate = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
        "\n",
        "for i in list_learning_rate:\n",
        "  print(\"Learning rate: \", i)\n",
        "  model = GradientBoostingClassifier(learning_rate = i)\n",
        "  trained_model = evaluate_model(model)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  1\n",
            "Train Score: 1.0\n",
            "Test Score:0.7165354330708661\n",
            "\n",
            "Learning rate:  0.5\n",
            "Train Score: 1.0\n",
            "Test Score:0.7401574803149606\n",
            "\n",
            "Learning rate:  0.25\n",
            "Train Score: 1.0\n",
            "Test Score:0.7480314960629921\n",
            "\n",
            "Learning rate:  0.1\n",
            "Train Score: 1.0\n",
            "Test Score:0.7559055118110236\n",
            "\n",
            "Learning rate:  0.05\n",
            "Train Score: 1.0\n",
            "Test Score:0.7480314960629921\n",
            "\n",
            "Learning rate:  0.01\n",
            "Train Score: 0.9050131926121372\n",
            "Test Score:0.7244094488188977\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6yaZWYKWCEb",
        "colab_type": "text"
      },
      "source": [
        "* El valor óptimo encontrado es un learning rate de 0.1. Las ventahas de un aprendizaje rápido es el ajuste rápido del modelo de una manera más general que si el parendizaje fuera mas lento y por lo tanto un numero mas bajo. Sin embargo el que el aprendizaje lento puede caer en sobreajuste y bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9YIZ0-jFLZ7",
        "colab_type": "text"
      },
      "source": [
        "## 3.   Repite el Boosting usando valores para el *number of trees*: 1, 2, 4, 8, 16, 32, 64, 100, 200. Utiliza alguna medida apropiada para medir la efectividad del modelo en cada caso y busca un valor óptimo. **Explica las ventajas y desventajas de usar muchos o pocos árboles**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBv216xjFRrU",
        "colab_type": "code",
        "outputId": "b423cb8f-d77a-4126-96b2-052ec3590f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "list_learning_rate2 = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
        "\n",
        "for i in list_learning_rate2:\n",
        "  print(\"Number of trees: \", i)\n",
        "  model = GradientBoostingClassifier(n_estimators=i)\n",
        "  trained_model = evaluate_model(model)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trees:  1\n",
            "Train Score: 0.7757255936675461\n",
            "Test Score:0.6692913385826772\n",
            "\n",
            "Number of trees:  2\n",
            "Train Score: 0.8284960422163589\n",
            "Test Score:0.7007874015748031\n",
            "\n",
            "Number of trees:  4\n",
            "Train Score: 0.862796833773087\n",
            "Test Score:0.7165354330708661\n",
            "\n",
            "Number of trees:  8\n",
            "Train Score: 0.8918205804749341\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Number of trees:  16\n",
            "Train Score: 0.941952506596306\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Number of trees:  32\n",
            "Train Score: 0.9868073878627969\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Number of trees:  64\n",
            "Train Score: 1.0\n",
            "Test Score:0.7480314960629921\n",
            "\n",
            "Number of trees:  100\n",
            "Train Score: 1.0\n",
            "Test Score:0.7559055118110236\n",
            "\n",
            "Number of trees:  200\n",
            "Train Score: 1.0\n",
            "Test Score:0.7401574803149606\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR8Mfom9Zycr",
        "colab_type": "text"
      },
      "source": [
        "* El valor óptimo de números de árboles es 100. Las ventajas de usar muchos arboles es que las estimaciones se adaptan más a los datos pero una desventaja que se pueden sobre-adaptar los datos de entrenamiento y ya no rindan en el test. Las ventajas de usar pocos árboles es que no se sobre-ajustan los datos pero también la data no es procesada lo suficiente para subir el score del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEbwTPIZFM29",
        "colab_type": "text"
      },
      "source": [
        "## 4.   Repite el Boosting usando valores para el *max_depth*: entre 1 y 32, enteros. Utiliza alguna medida apropiada para medir la efectividad del modelo en cada caso y busca un valor óptimo. **Explica las ventajas y desventajas de usar una profundidad muy alta o muy baja**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aon_-8ekFOCs",
        "colab_type": "code",
        "outputId": "cd6be50d-25ad-4037-e278-ea859f4e8cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2193
        }
      },
      "source": [
        "list_learning_rate3 = range(1, 33)\n",
        "\n",
        "for i in list_learning_rate3:\n",
        "  print(\"Max Depth: \", i)\n",
        "  model = GradientBoostingClassifier(max_depth = i)\n",
        "  trained_model = evaluate_model(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Depth:  1\n",
            "Train Score: 0.8733509234828496\n",
            "Test Score:0.6850393700787402\n",
            "\n",
            "Max Depth:  2\n",
            "Train Score: 1.0\n",
            "Test Score:0.7401574803149606\n",
            "\n",
            "Max Depth:  3\n",
            "Train Score: 1.0\n",
            "Test Score:0.7559055118110236\n",
            "\n",
            "Max Depth:  4\n",
            "Train Score: 1.0\n",
            "Test Score:0.7007874015748031\n",
            "\n",
            "Max Depth:  5\n",
            "Train Score: 1.0\n",
            "Test Score:0.7401574803149606\n",
            "\n",
            "Max Depth:  6\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  7\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  8\n",
            "Train Score: 1.0\n",
            "Test Score:0.7480314960629921\n",
            "\n",
            "Max Depth:  9\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  10\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  11\n",
            "Train Score: 1.0\n",
            "Test Score:0.7401574803149606\n",
            "\n",
            "Max Depth:  12\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  13\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  14\n",
            "Train Score: 1.0\n",
            "Test Score:0.7401574803149606\n",
            "\n",
            "Max Depth:  15\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  16\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  17\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  18\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  19\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  20\n",
            "Train Score: 1.0\n",
            "Test Score:0.7401574803149606\n",
            "\n",
            "Max Depth:  21\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  22\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  23\n",
            "Train Score: 1.0\n",
            "Test Score:0.7401574803149606\n",
            "\n",
            "Max Depth:  24\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  25\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  26\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  27\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  28\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n",
            "Max Depth:  29\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  30\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  31\n",
            "Train Score: 1.0\n",
            "Test Score:0.7244094488188977\n",
            "\n",
            "Max Depth:  32\n",
            "Train Score: 1.0\n",
            "Test Score:0.7322834645669292\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uix2ZkLCbybm",
        "colab_type": "text"
      },
      "source": [
        "* Hubo una mayor efectividad del modelo en la max depth de 3.\n",
        "Las ventajas que la profundidad maxima sea baja es que los datos no se van a sobreajustan pero también puede que no estemos viendo el minimo global. La ventaja de tener una mayor profundidad es que puede ajustarse más a la data para poder tener mejor calificación en total pero puede sobreajustarse."
      ]
    }
  ]
}